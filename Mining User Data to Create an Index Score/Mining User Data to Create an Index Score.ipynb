{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mining User Data to Create an Index Score \n",
    "\n",
    "The factor analysis behind creating an index score can be quite subjective and complicated. One method of generating insights towards factor analysis is to collect and describe data that can help one to analyze connections between factors and outcomes. \n",
    "\n",
    "In this report, I analyze factors in a bank's customer data [practice dataset] towards helping to inform the development of a credit scoring system. I seek to analyze a customer's behavior and several customer factors (such as their martical status and family size) and how these might influence their ability to repay a loan. This report answers questions such as: \n",
    "\n",
    "- Is there a relation between having kids and repaying a loan on time?\n",
    "- Is there a relation between marital status and repaying a loan on time?\n",
    "- Is there a relation between income level and repaying a loan on time?\n",
    "- How do different loan purposes affect on-time repayment of the loan?\n",
    "\n",
    "At the conclusion of our analysis, this report is able to recommend that the bank further explore making changes to their credit system based on several insights and predicted impact of customer factors in their ability to repay a loan. This may include tweaking their offers on loan amount and interest amounts based off of the following client information:  \n",
    "\n",
    "- Family Size \n",
    "- Marital Status \n",
    "- Income \n",
    "- Loan Purpose\n",
    "\n",
    "This report showed that the proportion of clients who had defaulted on a loan payment was different than the proportion of clients who had not defaulted on a loan, when disaggregated by family size, marital status, income and loan purpose. The difference was typically around 2% for certain factors; for example, we saw that clients who had 0 children, were a widow/widower and took out loans for real estate were less likely to default on a payment. Not surprisingly, we did observe a linear relationship between debt history and income. Our data analysis showed that clients who earned more, were less likely to have defaulted on a loan payment. It is important to dive deeper into this data, and we recommend that the bank define high-income earners and low-income earners, for example. This will help data analysts understand how to weigh the risks and offers to clients in the future. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inspecting Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing pandas library\n",
    "import pandas as pd\n",
    "# Connecting data source \n",
    "data = pd.read_csv('credit_scoring_eng.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 21525 entries, 0 to 21524\n",
      "Data columns (total 12 columns):\n",
      "children            21525 non-null int64\n",
      "days_employed       19351 non-null float64\n",
      "dob_years           21525 non-null int64\n",
      "education           21525 non-null object\n",
      "education_id        21525 non-null int64\n",
      "family_status       21525 non-null object\n",
      "family_status_id    21525 non-null int64\n",
      "gender              21525 non-null object\n",
      "income_type         21525 non-null object\n",
      "debt                21525 non-null int64\n",
      "total_income        19351 non-null float64\n",
      "purpose             21525 non-null object\n",
      "dtypes: float64(2), int64(5), object(5)\n",
      "memory usage: 2.0+ MB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>children</th>\n",
       "      <th>days_employed</th>\n",
       "      <th>dob_years</th>\n",
       "      <th>education</th>\n",
       "      <th>education_id</th>\n",
       "      <th>family_status</th>\n",
       "      <th>family_status_id</th>\n",
       "      <th>gender</th>\n",
       "      <th>income_type</th>\n",
       "      <th>debt</th>\n",
       "      <th>total_income</th>\n",
       "      <th>purpose</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-8437.673028</td>\n",
       "      <td>42</td>\n",
       "      <td>bachelor's degree</td>\n",
       "      <td>0</td>\n",
       "      <td>married</td>\n",
       "      <td>0</td>\n",
       "      <td>F</td>\n",
       "      <td>employee</td>\n",
       "      <td>0</td>\n",
       "      <td>40620.102</td>\n",
       "      <td>purchase of the house</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-4024.803754</td>\n",
       "      <td>36</td>\n",
       "      <td>secondary education</td>\n",
       "      <td>1</td>\n",
       "      <td>married</td>\n",
       "      <td>0</td>\n",
       "      <td>F</td>\n",
       "      <td>employee</td>\n",
       "      <td>0</td>\n",
       "      <td>17932.802</td>\n",
       "      <td>car purchase</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>-5623.422610</td>\n",
       "      <td>33</td>\n",
       "      <td>Secondary Education</td>\n",
       "      <td>1</td>\n",
       "      <td>married</td>\n",
       "      <td>0</td>\n",
       "      <td>M</td>\n",
       "      <td>employee</td>\n",
       "      <td>0</td>\n",
       "      <td>23341.752</td>\n",
       "      <td>purchase of the house</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>-4124.747207</td>\n",
       "      <td>32</td>\n",
       "      <td>secondary education</td>\n",
       "      <td>1</td>\n",
       "      <td>married</td>\n",
       "      <td>0</td>\n",
       "      <td>M</td>\n",
       "      <td>employee</td>\n",
       "      <td>0</td>\n",
       "      <td>42820.568</td>\n",
       "      <td>supplementary education</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>340266.072047</td>\n",
       "      <td>53</td>\n",
       "      <td>secondary education</td>\n",
       "      <td>1</td>\n",
       "      <td>civil partnership</td>\n",
       "      <td>1</td>\n",
       "      <td>F</td>\n",
       "      <td>retiree</td>\n",
       "      <td>0</td>\n",
       "      <td>25378.572</td>\n",
       "      <td>to have a wedding</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   children  days_employed  dob_years            education  education_id  \\\n",
       "0         1   -8437.673028         42    bachelor's degree             0   \n",
       "1         1   -4024.803754         36  secondary education             1   \n",
       "2         0   -5623.422610         33  Secondary Education             1   \n",
       "3         3   -4124.747207         32  secondary education             1   \n",
       "4         0  340266.072047         53  secondary education             1   \n",
       "\n",
       "       family_status  family_status_id gender income_type  debt  total_income  \\\n",
       "0            married                 0      F    employee     0     40620.102   \n",
       "1            married                 0      F    employee     0     17932.802   \n",
       "2            married                 0      M    employee     0     23341.752   \n",
       "3            married                 0      M    employee     0     42820.568   \n",
       "4  civil partnership                 1      F     retiree     0     25378.572   \n",
       "\n",
       "                   purpose  \n",
       "0    purchase of the house  \n",
       "1             car purchase  \n",
       "2    purchase of the house  \n",
       "3  supplementary education  \n",
       "4        to have a wedding  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Inspecting data\n",
    "data.info()\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data has quite a bit of information regarding the banks clients that potentially speak to their ability to repay a loan in a timely manner. Before trying to build a credit scoring system, the data needs to be cleaned as there are several pre-processing issues."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Processing missing values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When we encounter new datasets and data sources, as is the case here, it is important to sift through the data and look for missing values. Some missing values may be missing at random (MAR), missing completely at random (MCAR) or missing not at random (MNAR). \n",
    "\n",
    "We'll need to identify where there are missing values and look for any patterns that we might need to address. Otherwise, we'll have to fill the missing values, most importantly for columns where we will be applying data analysis methods. \n",
    "\n",
    "In order to check for missing values such as NaN and None values, we can employ two different methods. One method uses value_counts() and the other uses isnull() to check for missing values. We could use both or one. We'll start by using the value_counts() method and isnull() later on. By using value_count(), we'll also get a head start on identifying duplicate values and noticing patterns in the data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 0     14149\n",
      " 1      4818\n",
      " 2      2055\n",
      " 3       330\n",
      " 20       76\n",
      "-1        47\n",
      " 4        41\n",
      " 5         9\n",
      "Name: children, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Let's begin by using the value_counts() method and run every column\n",
    "print(data['children'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In analyzing the first column, we see there is a '-1' listed as a possibility for the number of children. For today's analysis, we will assume that the negative sign is a mistake and will replace it with '1.' We can feel comfortable in making this decision due to the unlikelihood that a client meant to share they had negative one child at the time of providing information the bank. The other error we see is that the data says there are 76 clients with 20 children - this is also most likely an error due to an extra zero. We will go ahead and delete the negative sign and 0 for today's data analysis. \n",
    "\n",
    "In working further with the bank, we may seek to find out why these errors appeared and how to ensure they don't occur again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replacing -1 with 1 and replacing the 20 with 2\n",
    "data['children'] = data['children'].replace({-1:1, 20:2})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-986.927316     1\n",
      "-7026.359174    1\n",
      "-4236.274243    1\n",
      "-6620.396473    1\n",
      "-1238.560080    1\n",
      "               ..\n",
      "-2849.351119    1\n",
      "-5619.328204    1\n",
      "-448.829898     1\n",
      "-1687.038672    1\n",
      "-582.538413     1\n",
      "Name: days_employed, Length: 19351, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(data['days_employed'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see more negatives here, in such volume that it becomes clear they are extra symbols that should be deleted. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35    617\n",
      "40    609\n",
      "41    607\n",
      "34    603\n",
      "38    598\n",
      "42    597\n",
      "33    581\n",
      "39    573\n",
      "31    560\n",
      "36    555\n",
      "44    547\n",
      "29    545\n",
      "30    540\n",
      "48    538\n",
      "37    537\n",
      "50    514\n",
      "43    513\n",
      "32    510\n",
      "49    508\n",
      "28    503\n",
      "45    497\n",
      "27    493\n",
      "56    487\n",
      "52    484\n",
      "47    480\n",
      "54    479\n",
      "46    475\n",
      "58    461\n",
      "57    460\n",
      "53    459\n",
      "51    448\n",
      "59    444\n",
      "55    443\n",
      "26    408\n",
      "60    377\n",
      "25    357\n",
      "61    355\n",
      "62    352\n",
      "63    269\n",
      "64    265\n",
      "24    264\n",
      "23    254\n",
      "65    194\n",
      "66    183\n",
      "22    183\n",
      "67    167\n",
      "21    111\n",
      "0     101\n",
      "68     99\n",
      "69     85\n",
      "70     65\n",
      "71     58\n",
      "20     51\n",
      "72     33\n",
      "19     14\n",
      "73      8\n",
      "74      6\n",
      "75      1\n",
      "Name: dob_years, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(data['dob_years'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we notice 101 entries for clients of the age \"0\". Are these different types of accounts that fall under another person's account? Or are these missing values that were input as 0? It is difficult to say what we should do with these values unless we speak to the bank directly. Since we won't be using this column for our data analysis, we'll leave it untouched for now. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "secondary education    13750\n",
      "bachelor's degree       4718\n",
      "SECONDARY EDUCATION      772\n",
      "Secondary Education      711\n",
      "some college             668\n",
      "BACHELOR'S DEGREE        274\n",
      "Bachelor's Degree        268\n",
      "primary education        250\n",
      "Some College              47\n",
      "SOME COLLEGE              29\n",
      "PRIMARY EDUCATION         17\n",
      "Primary Education         15\n",
      "graduate degree            4\n",
      "GRADUATE DEGREE            1\n",
      "Graduate Degree            1\n",
      "Name: education, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(data['education'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data will often be joined with other data, worked on by different people and during this process we can observe discrepancies in spelling. Here we notice that lower() might come in handy to make the data match. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "secondary education    15233\n",
      "bachelor's degree       5260\n",
      "some college             744\n",
      "primary education        282\n",
      "graduate degree            6\n",
      "Name: education, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "data['education'] = data['education'].str.lower()\n",
    "print(data['education'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1    15233\n",
      "0     5260\n",
      "2      744\n",
      "3      282\n",
      "4        6\n",
      "Name: education_id, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(data['education_id'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "married              12380\n",
      "civil partnership     4177\n",
      "unmarried             2813\n",
      "divorced              1195\n",
      "widow / widower        960\n",
      "Name: family_status, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(data['family_status'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    12380\n",
      "1     4177\n",
      "4     2813\n",
      "3     1195\n",
      "2      960\n",
      "Name: family_status_id, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(data['family_status_id'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F      14236\n",
      "M       7288\n",
      "XNA        1\n",
      "Name: gender, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(data['gender'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "employee                       11119\n",
      "business                        5085\n",
      "retiree                         3856\n",
      "civil servant                   1459\n",
      "unemployed                         2\n",
      "entrepreneur                       2\n",
      "paternity / maternity leave        1\n",
      "student                            1\n",
      "Name: income_type, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(data['income_type'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    19784\n",
      "1     1741\n",
      "Name: debt, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(data['debt'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17312.717    2\n",
      "31791.384    2\n",
      "42413.096    2\n",
      "54857.666    1\n",
      "26935.722    1\n",
      "            ..\n",
      "48796.341    1\n",
      "34774.610    1\n",
      "15710.698    1\n",
      "19232.334    1\n",
      "9591.824     1\n",
      "Name: total_income, Length: 19348, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(data['total_income'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wedding ceremony                            797\n",
      "having a wedding                            777\n",
      "to have a wedding                           774\n",
      "real estate transactions                    676\n",
      "buy commercial real estate                  664\n",
      "housing transactions                        653\n",
      "buying property for renting out             653\n",
      "transactions with commercial real estate    651\n",
      "housing                                     647\n",
      "purchase of the house                       647\n",
      "purchase of the house for my family         641\n",
      "construction of own property                635\n",
      "property                                    634\n",
      "transactions with my real estate            630\n",
      "building a real estate                      626\n",
      "buy real estate                             624\n",
      "purchase of my own house                    620\n",
      "building a property                         620\n",
      "housing renovation                          612\n",
      "buy residential real estate                 607\n",
      "buying my own car                           505\n",
      "going to university                         496\n",
      "car                                         495\n",
      "second-hand car purchase                    489\n",
      "to own a car                                480\n",
      "buying a second-hand car                    479\n",
      "cars                                        478\n",
      "to buy a car                                472\n",
      "car purchase                                462\n",
      "supplementary education                     462\n",
      "purchase of a car                           455\n",
      "university education                        453\n",
      "to get a supplementary education            447\n",
      "education                                   447\n",
      "getting an education                        443\n",
      "profile education                           436\n",
      "getting higher education                    426\n",
      "to become educated                          412\n",
      "Name: purpose, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(data['purpose'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we see that several purposes for taking out a loan that could be matched, such as \"car\" and \"cars\". "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['days_employed', 'total_income'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Let's use isnull() as the next step in our data preprocessing to look for missing values\n",
    "print(data.columns[data.isnull().any()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After looking more closely, we see how interesting this bank data is. It spans details about a client's income and lifestyle. Although there was some missing values here and there, and there is still some lingering questions we would need to ask the bank to clean up the data, this dataset looks like a great place to start finding patterns. Hopefully these patterns can help us build a credit scoring system and predict what types of clients are more likely to be good candidates for loans and other bank services. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data type replacement"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By using isnull() in the previous step, we find that client information for the number of days they've been employed and their income size is missing for some records. We'll want to replace or fill these missing values depending on how we conduct later data analysis and we should also seek to find out if there is a connection between the missing values. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Income Size* \n",
    "Income information is listed as a quantitative variable. Missing values in quantitative variables are filled with representative values. These values represent the status of the data set selected for analysis. To estimate the typical income size and replace the missing values in this column, we'll use the average income size (we might also look to use the median in another case)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replacing missing values in the column showing income size of a client \n",
    "# Creating a representative value first and saving it to total_income_avg\n",
    "total_income_avg = data['total_income'].mean()\n",
    "data['total_income'] = data['total_income'].fillna(value = total_income_avg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Employment History* \n",
    "When it comes to employment history, we can also fill the missing values with the average number of days employed for the group as a whole. This is a temporary fix, as we won't actually be using this data for our analysis. This is because further exploration reveals that the days_employed column has many faults, not just the additional negative signs, the missing values, but also impossible data. When we print this column to show the highest values first, we find that some clients have around 40,000 days employed, which comes to out around 1096 years. This is quite impossible! \n",
    "\n",
    "Let's take a look below and see for ourselves. We'll also go ahead and make a couple of corrections, like changing the data type from float to integer and filling the missing rows with the average number of days employed. \n",
    "\n",
    "(With correct data, we would first delete the negatives and then fill missing values with the median of the column. The median is less sensitive to outliers). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6954     401755.400475\n",
      "10006    401715.811749\n",
      "7664     401675.093434\n",
      "2156     401674.466633\n",
      "7794     401663.850046\n",
      "Name: days_employed, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Sorting values for 'days_employed' to show the highest values \n",
    "print(data.sort_values(by='days_employed', ascending=False)['days_employed'].head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Changing data type from float to integer\n",
    "data['days_employed'] = round(data['days_employed'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replacing missing values in the column showing the number of days a client has been employed\n",
    "# Creating a representative value first and saving it to days_employed_avg\n",
    "days_employed_avg = data['days_employed'].mean()\n",
    "data['days_employed'] = data['days_employed'].fillna(value = days_employed_avg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After seeing the impossible values in the days_employed column, we can brainstorm reasons why these values are so large. One hypothesis is that the decimal is placed incorrectly. In order to confirm this hypothesis, we would need to consult with the bank and make the correct changes. In the meantime, we're satisfied with having changed the data type and filling in the missing values. \n",
    "\n",
    "Now that we have replaced missing values in the data for income size, we can feel confident in performing future calculations that integrate this information. Now, before we move on to identifying patterns in the data, we should make sure that we don't have any duplicate data. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Processing duplicates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next step in our data preprocessing will be to delete duplicate values. We might be curious to see what, if any, columns have duplicates. To spot duplicates, we will used duplicated() to highlight the rows that have duplicate values across most of the columns in our dataset. This would indicate that the higlighted row has a duplicate and should be removed. We will then follow up by using drop_duplicates(), followed by reset_index() to avoid creating a column with old index values. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21525\n"
     ]
    }
   ],
   "source": [
    "# Counting number of rows before dropping duplicates\n",
    "print(len(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False    21454\n",
      "True        71\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Spot duplicates \n",
    "duplicate_data = data.duplicated(subset = ['children', 'days_employed', 'dob_years', 'education', 'family_status', 'gender', 'income_type', 'debt', 'total_income', 'purpose'], keep = 'first') \n",
    "print(duplicate_data.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete duplicate rows \n",
    "data = data.drop_duplicates(['children', 'days_employed', 'dob_years', 'education', 'family_status', 'gender', 'income_type', 'debt', 'total_income', 'purpose']).reset_index(drop = True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21454\n"
     ]
    }
   ],
   "source": [
    "# Counting number of rows after dropping duplicates\n",
    "print(len(data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perfect! We now have data rid of duplicate values. 71 duplicates to be exact. We decided to use drop_duplicates as an easy way to spot the 71 duplicate rows. We used multiple columns (most) to filter and ensure that we were really deleting duplicate entries. These 71 rows are most likely entries that were made twice at the time a client opened up an account at this bank. There are far too many similarities in all of the columns to indicate any other hypothesis for why the duplicate rows were in this dataseet. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Categorizing Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that our data has been prepared for analysis, we can really get started on finding patterns and trying to make insights. The data has information on client's loan history and if they were able to repay the loan on time. Since the bank would like to generally understand borrower's risk of defaulting, we will definitely want to break out our analysis by loan type. Do clients who take out loans for weddings pay their loan back more often than those who take out loans for real estate purposes? \n",
    "\n",
    "To answer this question and several others, we'll start by grouping our loans by type or category. In the code below, we will use replace() to group similar loan types all under once identifier. For example, both 'buying my own car' and 'second-hand car purchase' are now both identified by the string, 'car'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a new column 'purpose_grouped' to house the categories for grouped loan types \n",
    "data['purpose_grouped'] = data['purpose']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "real estate    10811\n",
      "car             4306\n",
      "education       4013\n",
      "wedding         2324\n",
      "Name: purpose_grouped, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Grouping loan types under the categories 'wedding', 'real estate', 'car' and 'education'\n",
    "data['purpose_grouped'] = data['purpose_grouped'].replace({'wedding ceremony':'wedding', 'having a wedding':'wedding', 'to have a wedding':'wedding'})\n",
    "data['purpose_grouped'] = data['purpose_grouped'].replace({'real estate transactions':'real estate', 'buy commercial real estate':'real estate', 'housing transactions':'real estate', 'buying property for renting out':'real estate', 'housing transactions':'real estate', 'transactions with commercial real estate':'real estate', 'purchase of the house':'real estate', 'housing':'real estate', 'purchase of the house for my family':'real estate', 'construction of own property':'real estate','property':'real estate','transactions with my real estate':'real estate','building a real estate':'real estate','buy real estate':'real estate','purchase of my own house':'real estate','building a property':'real estate','housing renovation':'real estate','buy residential real estate':'real estate'})\n",
    "data['purpose_grouped'] = data['purpose_grouped'].replace({'buying my own car':'car','car':'car','second-hand car purchase':'car','to own a car':'car','respon':'car','buying a second-hand car':'car','cars':'car','to buy a car':'car','car purchase':'car','purchase of a car':'car'})\n",
    "data['purpose_grouped'] = data['purpose_grouped'].replace({'going to university':'education', 'supplementary education':'education', 'university education':'education', 'to get a supplementary education':'education', 'getting an education':'education', 'profile education':'education', 'getting higher education':'education', 'to become educated':'education'})\n",
    "# Print(data.head(5))\n",
    "print(data['purpose_grouped'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great! All of our loan types are now in neat categories that will help us in the next steps. The variations in how the loan types were written (i.e., car and cars) may have arisen from different contributions made by information architects or database managers. Over the years, the identifiers for loan types may have changed. \n",
    "\n",
    "We also see that loans due to real estate purposes are by far the most frequent type of loan managed by this bank. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### - Is there a relation between having kids and repaying a loan on time?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To answer this question we'll want to use a pivot table. Pivot tables work well when it comes to presenting and synthesizing data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting children data type to object \n",
    "data['children'] = data['children'].astype('object')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a pivot table\n",
    "pivot_children = pd.pivot_table(data, index = ['children'], \n",
    "                                values = ['debt'], aggfunc = [np.sum, len])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('sum', 'debt')\n",
      "('len', 'debt')\n"
     ]
    }
   ],
   "source": [
    "# Here I am iterating the data columns names for my own understand of syntax\n",
    "for col in pivot_children.columns: \n",
    "    print(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>sum</th>\n",
       "      <th>len</th>\n",
       "      <th>proportion</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>debt</th>\n",
       "      <th>debt</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>children</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>41</td>\n",
       "      <td>9.756098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>202</td>\n",
       "      <td>2128</td>\n",
       "      <td>9.492481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>445</td>\n",
       "      <td>4855</td>\n",
       "      <td>9.165808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>27</td>\n",
       "      <td>330</td>\n",
       "      <td>8.181818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1063</td>\n",
       "      <td>14091</td>\n",
       "      <td>7.543822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           sum    len proportion\n",
       "          debt   debt           \n",
       "children                        \n",
       "4            4     41   9.756098\n",
       "2          202   2128   9.492481\n",
       "1          445   4855   9.165808\n",
       "3           27    330   8.181818\n",
       "0         1063  14091   7.543822\n",
       "5            0      9   0.000000"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Adding a column showing the proportion of clients who have defaulted on a loan payment\n",
    "pivot_children['proportion'] = (pivot_children[('sum','debt')]/pivot_children[('len', 'debt')])*100\n",
    "pivot_children.sort_values(by='proportion', ascending = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The pivot table above shows that of clients\n",
    "- reporting 4 children, only 9.76% have ever defaulted on a loan payment. \n",
    "- reporting 2 children, only 9.49% have ever defaulted on a loan payment. \n",
    "- reporting 1 children, only 9.17% have ever defaulted on a loan payment. \n",
    "- reporting 3 children, only 8.18% have ever defaulted on a loan payment. \n",
    "- reporting 0 children, only 7.54% have ever defaulted on a loan payment. \n",
    "\n",
    "It is not recommended to draw conclusions regarding clients reporting 5 children, because the size is small (n = 9) and we cannot speak as to it's validity as a representative sample. The other group sizes are large enough where we could conduct further data analysis. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The variations between proportions of clients with debt and no debt history when analyzed by family size are are not linear (I.e., the larger the family size, the more debt). In a lengthier data analysis, we may seek to run a t-test to find the correlation and strength of the correlation between the proportions. Through these statistical tests, we may find that there is a statistically significant difference between specific family sizes. This type of statistical test is not always appropriate or can be deemed unecessary, and the bank may not be seeking this type of analysis. \n",
    "\n",
    "For today's analysis, we  can conclude that there is no linear relationship between family size and debt history. We do howerver, observe small differences in between groups. For example, clients reporting 0 children are the least likely to default on a loan payment. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### - Is there a relation between marital status and repaying a loan on time?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a pivot table\n",
    "pivot_marital = pd.pivot_table(data, index = ['family_status'], \n",
    "                               values = ['debt'], aggfunc = [np.sum, len])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   sum    len proportion\n",
      "                  debt   debt           \n",
      "family_status                           \n",
      "unmarried          274   2810   9.750890\n",
      "civil partnership  388   4151   9.347145\n",
      "married            931  12339   7.545182\n",
      "divorced            85   1195   7.112971\n",
      "widow / widower     63    959   6.569343\n"
     ]
    }
   ],
   "source": [
    "# Adding a column showing the proportion of clients who have defaulted on a loan payment\n",
    "pivot_marital['proportion'] = (pivot_marital[('sum','debt')]/pivot_marital[('len', 'debt')])*100\n",
    "print(pivot_marital.sort_values(by='proportion', ascending = False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The pivot table above shows that of clients who are\n",
    "- in a civil partnership, only 9.35% have ever defaulted on a loan payment. \n",
    "- divorced, only 7.11% have ever defaulted on a loan payment. \n",
    "- married, only 7.55% have ever defaulted on a loan payment. \n",
    "- unmarried, only 9.75% have ever defaulted on a loan payment. \n",
    "- a widow/widower, only 6.57% have ever defaulted on a loan payment. \n",
    "\n",
    "There is hint of a potentially significant difference for clients reporting being a widow or widower and their loan repayment history. At 6.56% debt history, this group is the least likely to miss a loan payment. It also appears that unmarried clients have a bit higher rates of defaulting on a debt, coming in at 9.75%. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### - Is there a relation between income level and repaying a loan on time?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to answer this question, we should categorize this data to show groups of clients who are \"high income\" and those who are \"low income\". This categorization will help us to see patterns in the data in this analysis.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "362496.645\n",
      "3306.762\n"
     ]
    }
   ],
   "source": [
    "# We are first going to look at the minimum and maximum values for income \n",
    "# This will help us to know how we can build our function\n",
    "# In a more detailed data analysis, we may want to build a scatterplot or histogram as well\n",
    "print(data['total_income'].max())\n",
    "print(data['total_income'].min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a function to group incomes by type \n",
    "def income_function(income):\n",
    "    if income >= 100000:\n",
    "        return 'high'\n",
    "    if income >= 50000:\n",
    "        return 'medium'\n",
    "    if income >= 0:\n",
    "        return 'low'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a new column called total_income_grouped \n",
    "# Applying the income_function to the total_income column \n",
    "data['total_income_grouped'] = data['total_income'].apply(income_function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "low       20134\n",
      "medium     1221\n",
      "high         99\n",
      "Name: total_income_grouped, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Looking at how many clients in this dataset fall into low, medium high income \n",
    "print(data['total_income_grouped'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a pivot table\n",
    "pivot_income = pd.pivot_table(data, index = ['total_income_grouped'], \n",
    "                               values = ['debt'], aggfunc = [np.sum, len])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                       sum    len proportion\n",
      "                      debt   debt           \n",
      "total_income_grouped                        \n",
      "low                   1649  20134   8.190126\n",
      "medium                  86   1221   7.043407\n",
      "high                     6     99   6.060606\n"
     ]
    }
   ],
   "source": [
    "# Adding a column showing the proportion of clients who have defaulted on a loan payment\n",
    "pivot_income['proportion'] = (pivot_income[('sum','debt')]/pivot_income[('len', 'debt')])*100\n",
    "print(pivot_income.sort_values(by='proportion', ascending = False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The pivot table shows us a linear relationship between income size and debt history. This indicates that potentially, clients with higher incomes are less likely to default on a loan payment. \n",
    "\n",
    "In a lengthier data analysis and with more information from the bank, we would also want to test the strength of the correlation. In speaking with the bank further, we would want to clarify how they would like to define the different income groups (I.e., How much money does a high-income earner bring in?) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### - How do different loan purposes affect on-time repayment of the loan?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a pivot table \n",
    "pivot_purpose = pd.pivot_table(data, index = ['purpose_grouped'], \n",
    "                               values = ['debt'], aggfunc = [np.sum, len])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 sum    len proportion\n",
      "                debt   debt           \n",
      "purpose_grouped                       \n",
      "car              403   4306   9.359034\n",
      "education        370   4013   9.220035\n",
      "wedding          186   2324   8.003442\n",
      "real estate      782  10811   7.233373\n"
     ]
    }
   ],
   "source": [
    "#adding a column showing the proportion of clients who have defaulted on a loan payment\n",
    "pivot_purpose['proportion'] = (pivot_purpose[('sum','debt')]/pivot_purpose[('len', 'debt')])*100\n",
    "print(pivot_purpose.sort_values(by='proportion', ascending = False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The pivot table above shows that of clients who are seeking a loan related to \n",
    "- cars, only 9.36% have ever defaulted on a loan payment. \n",
    "- education, only 9.22% have ever defaulted on a loan payment. \n",
    "- real estate, only 7.23% have ever defaulted on a loan payment. \n",
    "- wedding, only 8.00% have ever defaulted on a loan payment. \n",
    "\n",
    "There is hint of a potentially significant difference for clients reporting taking out a loan for real estate and their loan repayment history. At 7.23% debt history, this group is the least likely to miss a loan payment. It also appears that clients taking out car loans have a bit higher rates of defaulting on a debt, coming in at 9.36%. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### General conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Overall, this report recommends that the bank has reason enough to further explore making changes to their credit system. This may include tweaking their offers on loan amount and interest amounts based off of the following client information:  \n",
    "\n",
    "- Family Size \n",
    "- Marital Status \n",
    "- Income \n",
    "- Loan Purpose\n",
    "\n",
    "We recommend that the bank create an index score that gives individual scores given to clients based off of their marital status, family size, income, and loan purpose. When aggregated, the index can be representative of the likelihood that a client will never miss a loan payment.\n",
    "\n",
    "This report showed that the proportion of clients who had defaulted on a loan payment was different than the proportion of clients who had not defaulted on a loan, when disaggregated by family size, marital status, income and loan purpose. \n",
    "\n",
    "The difference was typically around 2% for certain factors; for example, we saw that clients who had 0 children, were a widow/widower and took out loans for real estate were less likely to default on a payment. \n",
    "\n",
    "Not surprisingly, we did observe a linear relationship between debt history and income. Our data analysis showed that clients who earned more, were less likely to have defaulted on a loan payment. It is important to dive deeper into this data, and we recommend that the bank define high-income earners and low-income earners, for example. This will help data analysts understand how to weigh the risks and offers to clients in the future. \n",
    "\n",
    "The next step of data analysis, should include further discussion with the bank regarding their goals and data. The bank may seek to conduct further testing of stastitically significant differences between groups and build a credit index with varying degrees of weight on each factor. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
